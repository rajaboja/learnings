{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "WGAN.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNoxPfAz9gR+VT0snZBXAYg",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rajaboja/learnings/blob/master/WGAN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5O6whKDkexCa"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.datasets import MNIST\n",
        "from torch.optim import Adam\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm.auto import tqdm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i_G0OsYANqvP"
      },
      "source": [
        "class Generator(nn.Module):\n",
        "    def __init__(self,z_dim=10,out_chans=64):\n",
        "        super().__init__()\n",
        "        self.gen = nn.Sequential(\n",
        "            self.make_conv_block(z_dim,4*out_chans),\n",
        "            self.make_conv_block(4*out_chans,2*out_chans,kernel_size=4,stride=1),\n",
        "            self.make_conv_block(2*out_chans,out_chans),\n",
        "            self.make_conv_block(out_chans,1,kernel_size=4,final_layer=True)\n",
        "        )\n",
        "    def make_conv_block(self,in_chans,out_chans,kernel_size=3,stride=2,final_layer=False):\n",
        "        if not final_layer: \n",
        "            return nn.Sequential(\n",
        "                nn.ConvTranspose2d(in_chans,out_chans,kernel_size,stride),\n",
        "                nn.BatchNorm2d(out_chans),\n",
        "                nn.ReLU()\n",
        "            )\n",
        "        else:\n",
        "            return nn.Sequential(\n",
        "                nn.ConvTranspose2d(in_chans,out_chans,kernel_size,stride),\n",
        "                nn.Tanh()\n",
        "            )\n",
        "\n",
        "    def forward(self,inp):\n",
        "        inp = inp.view(inp.shape[0],inp.shape[1],1,1)\n",
        "        return self.gen(inp)\n",
        "\n",
        "\n",
        "def make_noise(num_samples,z_dim,device):\n",
        "    return torch.randn(num_samples,z_dim,device=device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eQyeavTlYabE"
      },
      "source": [
        "class Critic(nn.Module):\n",
        "    def __init__(self,image_chans=1,out_chans=64):\n",
        "        super().__init__()\n",
        "        self.crit = nn.Sequential(\n",
        "            self.make_crit_block(image_chans,out_chans),\n",
        "            self.make_crit_block(out_chans,2*out_chans),\n",
        "            self.make_crit_block(2*out_chans,1,final_layer=True)\n",
        "        )\n",
        "\n",
        "    def make_crit_block(self,in_chans,out_chans,kernel_size=4,stride=2,final_layer=False):\n",
        "        if not final_layer:\n",
        "            return nn.Sequential(\n",
        "                nn.Conv2d(in_chans,out_chans,kernel_size,stride),\n",
        "                nn.BatchNorm2d(out_chans),\n",
        "                nn.LeakyReLU(negative_slope=0.2)\n",
        "            )\n",
        "        else:\n",
        "            return nn.Sequential(nn.Conv2d(in_chans,out_chans,kernel_size,stride))\n",
        "\n",
        "    def forward(self,inp):\n",
        "        pred = self.crit(inp)\n",
        "        return pred.view(len(pred), -1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VOUWH-yfpDKI"
      },
      "source": [
        "z_dim=64\n",
        "bs=128\n",
        "if torch.cuda.is_available():device='cuda'\n",
        "else:device = 'cpu'\n",
        "\n",
        "tfms = transforms.Compose([transforms.ToTensor(),\n",
        "                           transforms.Normalize((0.5,),(0.5,))])\n",
        "\n",
        "dls = DataLoader(MNIST('.',download=True,transform=tfms),batch_size=bs,shuffle=True)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3tHQG4WWqoPl"
      },
      "source": [
        "gen = Generator(z_dim=z_dim).to(device)\n",
        "crit = Critic().to(device)\n",
        "\n",
        "gen_opt = Adam(gen.parameters(),betas=(0.5,0.999))\n",
        "crit_opt = Adam(crit.parameters(),betas=(0.5,0.999))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HjfeUnHgsvhu"
      },
      "source": [
        "def init(m):\n",
        "    if isinstance(m,nn.Conv2d) or isinstance(m,nn.ConvTranspose2d):\n",
        "        nn.init.normal_(m.weight,0.,0.02)\n",
        "    if isinstance(m,nn.BatchNorm2d):\n",
        "        nn.init.normal_(m.weight,0.,0.02)\n",
        "        nn.init.constant_(m.bias,0)\n",
        "\n",
        "gen = gen.apply(init)\n",
        "crit = crit.apply(init)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5YkK_OzHw_2e"
      },
      "source": [
        "def gredient_penalty(crit,real,fake,epsilon):\n",
        "    mix = epsilon*real+((1-epsilon)*fake)\n",
        "    mix_score = crit(mix)\n",
        "\n",
        "    grad = torch.autograd.grad(outputs=mix_score,inputs=mix,\n",
        "                               grad_outputs=torch.ones_like(mix_score),create_graph=True,retain_graph=True)[0]\n",
        "\n",
        "    grad = grad.view(len(grad),-1) \n",
        "    norm = grad.norm(2,dim=1)\n",
        "    penalty = torch.mean(torch.pow(norm-1,2))\n",
        "    return penalty"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vj0ZLYJnA-u9"
      },
      "source": [
        "def get_gen_loss(crit_fake_pred):\n",
        "    return -torch.mean(crit_fake_pred)\n",
        "def get_crit_loss(crit_fake_pred,crit_real_pred,gp,weight):\n",
        "    return torch.mean(crit_fake_pred)-torch.mean(crit_real_pred)+gp*weight"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SCjXJZRfobl2"
      },
      "source": [
        "from torchvision.utils import make_grid\n",
        "\n",
        "def show_tensor_images(image_tensor, num_images=25, size=(1, 28, 28)):\n",
        "    '''\n",
        "    Function for visualizing images: Given a tensor of images, number of images, and\n",
        "    size per image, plots and prints the images in an uniform grid.\n",
        "    '''\n",
        "    image_tensor = (image_tensor + 1) / 2\n",
        "    image_unflat = image_tensor.detach().cpu()\n",
        "    image_grid = make_grid(image_unflat[:num_images], nrow=5)\n",
        "    plt.imshow(image_grid.permute(1, 2, 0).squeeze())\n",
        "    plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vMYinCmj2pre"
      },
      "source": [
        "n_epochs = 100\n",
        "crit_reps = 5\n",
        "c_lambda =10\n",
        "cur_step = 0\n",
        "display_step = 500\n",
        "generator_losses = []\n",
        "critic_losses =[]\n",
        "\n",
        "for i in range(n_epochs):\n",
        "    for real,_ in tqdm(dls):\n",
        "        \n",
        "        real = real.to(device)\n",
        "        mean_iteration_critic_loss = 0\n",
        "        for _ in range(crit_reps):\n",
        "            crit_opt.zero_grad()\n",
        "            noise = make_noise(len(real),z_dim,device)\n",
        "            gen_out = gen(noise).detach()\n",
        "            crit_fake = crit(gen_out)\n",
        "            crit_real = crit(real)\n",
        "\n",
        "            epsilon = torch.rand(len(real),1,1,1,device=device,requires_grad=True)\n",
        "            # print(epsilon.shape, real.shape,gen_out.shape)\n",
        "            gp = gredient_penalty(crit,real,gen_out.detach(),epsilon)\n",
        "            # print(crit_fake.shape,crit_real.shape)\n",
        "            crit_loss = get_crit_loss(crit_fake,crit_real,gp,c_lambda)\n",
        "            mean_iteration_critic_loss += crit_loss.item() / crit_reps\n",
        "\n",
        "            crit_loss.backward(retain_graph=True)\n",
        "            crit_opt.step()\n",
        "        critic_losses+=[mean_iteration_critic_loss]\n",
        "\n",
        "        gen_opt.zero_grad()\n",
        "        noise_1 = make_noise(len(real),z_dim,device)\n",
        "        gen_out1 = gen(noise_1)\n",
        "        gen_loss = get_gen_loss(crit(gen_out1))\n",
        "        gen_loss.backward()\n",
        "        gen_opt.step()\n",
        "\n",
        "        generator_losses += [gen_loss.item()]\n",
        "\n",
        "        if cur_step % display_step == 0 and cur_step > 0:\n",
        "            gen_mean = sum(generator_losses[-display_step:]) / display_step\n",
        "            crit_mean = sum(critic_losses[-display_step:]) / display_step\n",
        "            print(f\"Step {cur_step}: Generator loss: {gen_mean}, critic loss: {crit_mean}\")\n",
        "            show_tensor_images(gen_out)\n",
        "            show_tensor_images(real)\n",
        "            step_bins = 20\n",
        "            num_examples = (len(generator_losses) // step_bins) * step_bins\n",
        "            plt.plot(\n",
        "                range(num_examples // step_bins), \n",
        "                torch.Tensor(generator_losses[:num_examples]).view(-1, step_bins).mean(1),\n",
        "                label=\"Generator Loss\"\n",
        "            )\n",
        "            plt.plot(\n",
        "                range(num_examples // step_bins), \n",
        "                torch.Tensor(critic_losses[:num_examples]).view(-1, step_bins).mean(1),\n",
        "                label=\"Critic Loss\"\n",
        "            )\n",
        "            plt.legend()\n",
        "            plt.show()\n",
        "\n",
        "        cur_step += 1\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}