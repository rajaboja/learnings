{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Conditional GAN.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "CefTl2krSsYJ"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision.datasets import MNIST\n",
        "from torchvision import transforms\n",
        "from tqdm.auto import tqdm\n",
        "import torch.nn.functional as F\n",
        "from torchvision.utils import make_grid\n",
        "import matplotlib.pyplot as plt\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DZu9BV20TSWb"
      },
      "source": [
        "class Generator(nn.Module):\n",
        "    def __init__(self,in_chans=10,out_chans=64):\n",
        "        super().__init__()\n",
        "        self.gen = nn.Sequential(\n",
        "            self.make_gen_block(in_chans,out_chans*4),\n",
        "            self.make_gen_block(4*out_chans,2*out_chans,kernel_size=4,stride=1),\n",
        "            self.make_gen_block(2*out_chans,out_chans),\n",
        "            self.make_gen_block(out_chans,1,kernel_size=4,final_layer=True)\n",
        "        )\n",
        "    def make_gen_block(self,in_chans,out_chans,kernel_size=3,stride=2,final_layer=False):\n",
        "        if not final_layer:\n",
        "            return nn.Sequential(\n",
        "                nn.ConvTranspose2d(in_chans,out_chans,kernel_size,stride),\n",
        "                nn.BatchNorm2d(out_chans),\n",
        "                nn.ReLU(inplace=True)\n",
        "            )\n",
        "        else:\n",
        "            return nn.Sequential(\n",
        "                nn.ConvTranspose2d(in_chans,out_chans,kernel_size,stride),\n",
        "                nn.Tanh()\n",
        "            )\n",
        "    def forward(self,inp):\n",
        "        inp = inp.view(inp.shape[0],inp.shape[1],1,1)                \n",
        "        return self.gen(inp)\n",
        "\n",
        "def make_noise(num_samples,in_dim,device):\n",
        "    return torch.randn(num_samples,in_dim,device=device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AzHkQ3X67Zfl"
      },
      "source": [
        "class Discriminator(nn.Module):\n",
        "    def __init__(self,in_chans=1,hid_dim=64):\n",
        "        super().__init__()\n",
        "        self.disc = nn.Sequential(\n",
        "            self.make_disc_block(in_chans,hid_dim),\n",
        "            self.make_disc_block(hid_dim,hid_dim*2),\n",
        "            self.make_disc_block(2*hid_dim,1,final_layer=True)\n",
        "        )\n",
        "        \n",
        "    def make_disc_block(self,in_chans,out_chans,kernel_size=3,stride=2,final_layer=False):\n",
        "        if not final_layer:\n",
        "            return nn.Sequential(\n",
        "                nn.Conv2d(in_chans,out_chans,kernel_size,stride),\n",
        "                nn.BatchNorm2d(out_chans),\n",
        "                nn.LeakyReLU(negative_slope=0.2,inplace=True)\n",
        "            )\n",
        "        else:\n",
        "            return nn.Sequential(\n",
        "                nn.Conv2d(in_chans,out_chans,kernel_size,stride),\n",
        "            )\n",
        "    def forward(self,inp):\n",
        "        out = self.disc(inp)\n",
        "        return out.view(len(out),-1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lxu9S3IHEEFJ"
      },
      "source": [
        "tfms = transforms.Compose([transforms.ToTensor(),\n",
        "                           transforms.Normalize((0.5,),(0.5,))])\n",
        "dset = MNIST('.',transform=tfms,download=True)\n",
        "dls = torch.utils.data.DataLoader(dset,batch_size=128,shuffle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KsGbcIfQNkb9"
      },
      "source": [
        "if torch.cuda.is_available():device='cuda'\n",
        "else:device='cpu'\n",
        "\n",
        "def init(m):\n",
        "    if isinstance(m,nn.Conv2d) or isinstance(m,nn.ConvTranspose2d):\n",
        "        nn.init.normal_(m.weight)\n",
        "    if isinstance(m,nn.BatchNorm2d):\n",
        "        nn.init.normal_(m.weight)\n",
        "        nn.init.constant_(m.bias,0.)\n",
        "\n",
        "z_dim = 64\n",
        "n_classes=10\n",
        "mnist_chans = 1\n",
        "\n",
        "in_dim = z_dim+n_classes\n",
        "disc_dim = mnist_chans+n_classes\n",
        "\n",
        "gen = Generator(in_chans=in_dim).to(device)\n",
        "disc = Discriminator(in_chans=disc_dim).to(device)\n",
        "\n",
        "gen_opt = torch.optim.Adam(gen.parameters(),betas=(0.5,0.999))\n",
        "disc_opt = torch.optim.Adam(disc.parameters(),betas = (0.5,0.999))\n",
        "\n",
        "gen=gen.apply(init)\n",
        "disc=disc.apply(init)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dfwy6io0qP2C"
      },
      "source": [
        "def show_tensor_images(image_tensor, num_images=25, size=(1, 28, 28), nrow=5, show=True):\n",
        "    '''\n",
        "    Function for visualizing images: Given a tensor of images, number of images, and\n",
        "    size per image, plots and prints the images in an uniform grid.\n",
        "    '''\n",
        "    image_tensor = (image_tensor + 1) / 2\n",
        "    image_unflat = image_tensor.detach().cpu()\n",
        "    image_grid = make_grid(image_unflat[:num_images], nrow=nrow)\n",
        "    plt.imshow(image_grid.permute(1, 2, 0).squeeze())\n",
        "    if show:\n",
        "        plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "S8wTeSpOBhZ6"
      },
      "source": [
        "n_epochs = 100\n",
        "loss = nn.BCEWithLogitsLoss()\n",
        "cur_step = 0\n",
        "display_step =500\n",
        "generator_losses = []\n",
        "discriminator_losses = []\n",
        "\n",
        "for i in range(n_epochs):\n",
        "    for real,labels in tqdm(dls):\n",
        "        real = real.to(device)\n",
        "        \n",
        "        one_hots = F.one_hot(labels.to(device),num_classes=10)\n",
        "        noise = make_noise(len(real),z_dim,device)\n",
        "        # print(noise)\n",
        "        combi_noise = torch.cat((noise,one_hots),dim=1)\n",
        "        fake_ims = gen(combi_noise)\n",
        "\n",
        "        image_oh = one_hots[:,:,None,None].repeat(1,1,real.shape[2],real.shape[3])\n",
        "        real_in = torch.cat((real,image_oh),dim=1)\n",
        "        fake_in = torch.cat((fake_ims,image_oh),dim=1)\n",
        "\n",
        "        preds_real = disc(real_in)\n",
        "        preds_fake = disc(fake_in.detach())\n",
        "\n",
        "        disc_opt.zero_grad()\n",
        "        disc_loss = (loss(preds_real,torch.ones_like(preds_real))+\n",
        "                     loss(preds_fake,torch.zeros_like(preds_fake)))/2\n",
        "        disc_loss.backward()\n",
        "        disc_opt.step()\n",
        "        discriminator_losses += [disc_loss.item()]\n",
        "\n",
        "        gen_opt.zero_grad()\n",
        "        preds =  disc(fake_in)\n",
        "        gen_loss = loss(preds,torch.ones_like(preds))\n",
        "        gen_loss.backward()\n",
        "        gen_opt.step()\n",
        "        generator_losses += [gen_loss.item()]\n",
        "        if cur_step % display_step == 0 and cur_step > 0:\n",
        "            gen_mean = sum(generator_losses[-display_step:]) / display_step\n",
        "            disc_mean = sum(discriminator_losses[-display_step:]) / display_step\n",
        "            print(f\"Step {cur_step}: Generator loss: {gen_mean}, discriminator loss: {disc_mean}\")\n",
        "            show_tensor_images(noise)\n",
        "            show_tensor_images(real)\n",
        "            step_bins = 20\n",
        "            x_axis = sorted([i * step_bins for i in range(len(generator_losses) // step_bins)] * step_bins)\n",
        "            num_examples = (len(generator_losses) // step_bins) * step_bins\n",
        "            plt.plot(\n",
        "                range(num_examples // step_bins), \n",
        "                torch.Tensor(generator_losses[:num_examples]).view(-1, step_bins).mean(1),\n",
        "                label=\"Generator Loss\"\n",
        "            )\n",
        "            plt.plot(\n",
        "                range(num_examples // step_bins), \n",
        "                torch.Tensor(discriminator_losses[:num_examples]).view(-1, step_bins).mean(1),\n",
        "                label=\"Discriminator Loss\"\n",
        "            )\n",
        "            plt.legend()\n",
        "            plt.show()\n",
        "        cur_step += 1\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PAKPLYvgqQgu"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}