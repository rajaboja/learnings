{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DC GAN.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyP9pZA9XlgNjAjV+lIso5dU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rajaboja/learnings/blob/master/DC_GAN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vyBErYVqD84A"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.datasets import MNIST\n",
        "from torchvision import transforms\n",
        "from tqdm.auto import tqdm\n",
        "from torchvision.utils import make_grid\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pv96sToPENu2"
      },
      "source": [
        "class Generator(nn.Module):\n",
        "    def __init__(self,z_dim=10,hid_dim=64,image_chan=1):\n",
        "        super().__init__()\n",
        "        self.gen =  nn.Sequential(\n",
        "            self.make_gen_block(z_dim,4*hid_dim),\n",
        "            self.make_gen_block(4*hid_dim,2*hid_dim,kernel_size=4,stride=1),\n",
        "            self.make_gen_block(2*hid_dim,hid_dim),\n",
        "            self.make_gen_block(hid_dim,image_chan,kernel_size=4,final_layer=True)\n",
        "        )\n",
        "    def make_gen_block(self,in_chans,out,kernel_size=3,stride=2,final_layer=False):\n",
        "        if not final_layer:\n",
        "            return nn.Sequential(\n",
        "                nn.ConvTranspose2d(in_chans,out,kernel_size,stride),\n",
        "                nn.BatchNorm2d(out),\n",
        "                nn.ReLU()\n",
        "            )\n",
        "        else: \n",
        "            return nn.Sequential(\n",
        "                nn.ConvTranspose2d(in_chans,out,kernel_size,stride),\n",
        "                nn.Tanh()\n",
        "            )\n",
        "    def forward(self,inp):\n",
        "        # print(inp.shape)\n",
        "        inp = inp.view(inp.shape[0],inp.shape[1],1,1)\n",
        "        return self.gen(inp)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cn6_h4GvXsPQ"
      },
      "source": [
        "def make_noise(num_images,z_dim,device):\n",
        "    return torch.randn((num_images,z_dim),device=device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H96iDNKLXzXX"
      },
      "source": [
        "class Discriminator(nn.Module):\n",
        "    def __init__(self,im_chans=1,hid_dim=16):\n",
        "        super().__init__()\n",
        "        self.disc = nn.Sequential(\n",
        "            self.make_disc_block(im_chans,hid_dim),\n",
        "            self.make_disc_block(hid_dim,2*hid_dim),\n",
        "            self.make_disc_block(2*hid_dim,1,final_layer=True)\n",
        "        )\n",
        "    \n",
        "    def make_disc_block(self,im_chans,out,kernel_size=4,stride=2, final_layer=False):\n",
        "        if not final_layer:\n",
        "            return nn.Sequential(\n",
        "                nn.Conv2d(im_chans,out,kernel_size,stride),\n",
        "                nn.BatchNorm2d(out),\n",
        "                nn.LeakyReLU(negative_slope=0.2)\n",
        "            )\n",
        "        else:\n",
        "            return nn.Sequential(\n",
        "                nn.Conv2d(im_chans,out,kernel_size,stride)\n",
        "            )\n",
        "\n",
        "    def forward(self,inp):\n",
        "        pred = self.disc(inp)\n",
        "        return pred.view(len(pred), -1)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5wapbi3b3GI0"
      },
      "source": [
        "loss = nn.BCEWithLogitsLoss()\n",
        "n_epochs=50\n",
        "lr=1e-3\n",
        "bs=128\n",
        "z_dim=64\n",
        "display_step=500\n",
        "\n",
        "if torch.cuda.is_available():device='cuda'\n",
        "else: device='cpu'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FTLMc-V64jtV"
      },
      "source": [
        "tfms = transforms.Compose([transforms.ToTensor(),\n",
        "                           transforms.Normalize((0.5,),(0.5,))])\n",
        "\n",
        "dls = DataLoader(MNIST('.',transform=tfms,download=True),batch_size=bs,shuffle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vUwMv31j7U5j"
      },
      "source": [
        "gen = Generator(z_dim).to(device)\n",
        "disc = Discriminator().to(device)\n",
        "\n",
        "gen_opt = torch.optim.Adam(gen.parameters(),lr=lr,betas=(0.5,0.999))\n",
        "disc_opt = torch.optim.Adam(disc.parameters(),lr=lr,betas=(0.5,0.999))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rckdSmUqMbml"
      },
      "source": [
        "def weights_init(m):\n",
        "    if isinstance(m, nn.Conv2d) or isinstance(m, nn.ConvTranspose2d):\n",
        "        torch.nn.init.normal_(m.weight, 0.0, 0.02)\n",
        "    if isinstance(m, nn.BatchNorm2d):\n",
        "        torch.nn.init.normal_(m.weight, 0.0, 0.02)\n",
        "        torch.nn.init.constant_(m.bias, 0)\n",
        "                      \n",
        "gen = gen.apply(weights_init)\n",
        "disc = disc.apply(weights_init)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zE96BMfZCokk"
      },
      "source": [
        "def show_tensor_images(image_tensor, num_images=25, size=(1, 28, 28)):\n",
        "\n",
        "    image_tensor = (image_tensor + 1) / 2\n",
        "    image_unflat = image_tensor.detach().cpu()\n",
        "    image_grid = make_grid(image_unflat[:num_images], nrow=5)\n",
        "    plt.imshow(image_grid.permute(1, 2, 0).squeeze())\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CCUey-ebOhUR"
      },
      "source": [
        "cur_step = 0\n",
        "mean_generator_loss = 0\n",
        "mean_discriminator_loss = 0\n",
        "\n",
        "for i in range(n_epochs):\n",
        "    for real,_ in tqdm(dls):\n",
        "        real = real.to(device)\n",
        "\n",
        "        disc_opt.zero_grad()\n",
        "        fake_noise = make_noise(len(real), z_dim, device=device)\n",
        "        fake = gen(fake_noise)\n",
        "        disc_fake_pred = disc(fake.detach())\n",
        "        disc_fake_loss = loss(disc_fake_pred, torch.zeros_like(disc_fake_pred))\n",
        "\n",
        "        disc_real_pred = disc(real)\n",
        "        disc_real_loss = loss(disc_real_pred, torch.ones_like(disc_real_pred))\n",
        "\n",
        "        disc_loss = (disc_fake_loss + disc_real_loss) / 2\n",
        "        mean_discriminator_loss += disc_loss.item() / display_step\n",
        "        \n",
        "        disc_loss.backward(retain_graph=True)\n",
        "        disc_opt.step()\n",
        "        \n",
        "        gen_opt.zero_grad()\n",
        "        disc_fake_pred = disc(fake)\n",
        "        gen_loss = loss(disc_fake_pred, torch.ones_like(disc_fake_pred))\n",
        "        gen_loss.backward()\n",
        "        gen_opt.step()        \n",
        "\n",
        "        mean_generator_loss += gen_loss.item() / display_step\n",
        "\n",
        "        if cur_step % display_step == 0 and cur_step > 0:\n",
        "            print(f\"Step {cur_step}: Generator loss: {mean_generator_loss}, discriminator loss: {mean_discriminator_loss}\")\n",
        "            show_tensor_images(fake)\n",
        "            show_tensor_images(real)\n",
        "            mean_generator_loss = 0\n",
        "            mean_discriminator_loss = 0\n",
        "        cur_step += 1\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}